{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = gensim.models.KeyedVectors.load('glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvRecurrentAttentionNet:\n",
    "    def __init__(self, embedding_model, seq_length, embedding_dim, filter_size, num_filters, hidden_size, batch_size, num_classes):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.seq_length = seq_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.filter_size = filter_size\n",
    "        self.num_filters = num_filters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        \n",
    "    def word_embedding(self, inputs, reuse=False):\n",
    "        with tf.variable_scope('word_embedding', reuse=reuse):\n",
    "            embedding_W = tf.get_variable('embedding_W',\n",
    "                                          shape=[self.embedding_model.vectors.shape[0], self.embedding_model.vectors.shape[1]],\n",
    "                                          initializer=tf.constant_initializer(self.embedding_model.vectors),\n",
    "                                          trainable=True)\n",
    "            \n",
    "            embedded_X = tf.nn.embedding_lookup(embedding_W, inputs)\n",
    "            \n",
    "        return embedded_X\n",
    "    \n",
    "\n",
    "    def attention_extraction(self, inputs, reuse=False):\n",
    "        with tf.variable_scope('attention_extraction', reuse=reuse):\n",
    "            input_reshaped = tf.reshape(inputs, [-1, self.seq_length, self.embedding_dim, 1])\n",
    "            paddings = tf.constant([[0, 0], [1, 1], [0, 0], [0, 0]], dtype='int32')\n",
    "            input_padded = tf.pad(input_reshaped, paddings, 'CONSTANT')\n",
    "            \n",
    "            filter_shape = [self.filter_size, self.embedding_dim, 1, self.num_filters]\n",
    "            \n",
    "            W = tf.get_variable('cnn_filter', \n",
    "                                shape=filter_shape, \n",
    "                                initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "            \n",
    "            b = tf.get_variable('cnn_bias',\n",
    "                                shape=[num_filters],\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "            \n",
    "            conv = tf.nn.conv2d(input=input_padded, \n",
    "                                filter=W, \n",
    "                                strides=[1, 1, 1, 1], \n",
    "                                padding='VALID',\n",
    "                                name='convolution')\n",
    "            \n",
    "            conv_output = tf.nn.relu(tf.nn.bias_add(conv, b), name='relu')\n",
    "            attention_signal = tf.reduce_mean(tf.transpose(tf.squeeze(conv_output), perm=[0, 2, 1]), \n",
    "                                              axis=1, \n",
    "                                              name='attention_signal')\n",
    "        \n",
    "        return attention_signal\n",
    "    \n",
    "    \n",
    "    def lstm_encoder(self, inputs, reuse=False):\n",
    "        with tf.variable_scope('lstm_encoder', reuse=reuse):\n",
    "            lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(self.hidden_size)\n",
    "            lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=0.5)\n",
    "            hiddens, _ = tf.nn.dynamic_rnn(lstm_cell, inputs, dtype=tf.float32)\n",
    "        \n",
    "        return hiddens\n",
    "    \n",
    "    \n",
    "    def classification(self, attention_signal, hiddens, reuse=False):\n",
    "        with tf.variable_scope('classification', reuse=reuse):    \n",
    "            whole_seq = tf.reduce_mean(tf.multiply(hiddens, tf.expand_dims(attention_signal, axis=2)), axis=1)\n",
    "            \n",
    "            W = tf.get_variable('output_weights', \n",
    "                                shape=[self.embedding_dim, self.num_classes], \n",
    "                                initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "            \n",
    "            b = tf.get_variable('output_bias',\n",
    "                                shape=[self.num_classes],\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "            \n",
    "            output = tf.nn.bias_add(tf.matmul(whole_seq, W), b)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def build_graph(self, inputs, reuse=False):\n",
    "        embedded_X = self.word_embedding(inputs, reuse=reuse)\n",
    "        attention_signal = self.attention_extraction(embedded_X, reuse=reuse)\n",
    "        hiddens = self.lstm_encoder(embedded_X, reuse=reuse)\n",
    "        output = self.classification(attention_signal, hiddens, reuse=reuse)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(serialized_example):\n",
    "    features = {\n",
    "        'document': tf.FixedLenFeature([18], tf.int64),\n",
    "        'label': tf.FixedLenFeature([6], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "\n",
    "    document = parsed_feature['document']\n",
    "    label = parsed_feature['label']\n",
    "\n",
    "    return document, label\n",
    "\n",
    "def read_tfrecord(fname, parser, shuffle_size, batch_size, seq_length):\n",
    "    dataset = tf.data.TFRecordDataset(fname).map(parser)\n",
    "    dataset = dataset.shuffle(shuffle_size, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "    feature, label = iterator.get_next()\n",
    "    feature = tf.reshape(feature, [-1, seq_length])\n",
    "    feature = tf.cast(feature, tf.int64)\n",
    "    return iterator, dataset, feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 18\n",
    "embedding_dim = 100\n",
    "filter_size = 3\n",
    "num_filters = 50\n",
    "hidden_size = 100\n",
    "batch_size = 16\n",
    "num_classes = 6\n",
    "\n",
    "train_data_dir = './train.tfrecord'\n",
    "shuffle_size = 100000\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model, seq_length, embedding_dim, filter_size, num_of_filters, hidden_size, batch_size, class_num\n",
    "\n",
    "model = ConvRecurrentAttentionNet(glove_model, seq_length, embedding_dim, filter_size, num_of_filters, hidden_size, batch_size, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "train_itr, train_dataset, train_X, train_y = read_tfrecord(train_data_dir, \n",
    "                                                           parser, \n",
    "                                                           shuffle_size, \n",
    "                                                           batch_size, \n",
    "                                                           seq_length)\n",
    "\n",
    "train_init_op = train_itr.make_initializer(train_dataset)\n",
    "\n",
    "X = tf.placeholder(tf.int64, [None, seq_length])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "\n",
    "logits = model.build_graph(X)\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits, name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "predict_proba = tf.nn.sigmoid(logits)\n",
    "\n",
    "auc = tf.metrics.auc(Y, predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 500, Cost: [[0.6931644  0.6931571  0.6931575  0.6931505  0.6931559  0.6931586 ]\n",
      " [0.6931612  0.6931513  0.69315153 0.69315094 0.6931548  0.6931571 ]\n",
      " [0.6931533  0.69315267 0.693155   0.69315344 0.693157   0.693154  ]\n",
      " [0.6931584  0.6931519  0.6931508  0.6931638  0.6931548  0.69315904]\n",
      " [0.69315934 0.6931547  0.6931505  0.69315493 0.6931546  0.6931602 ]\n",
      " [0.6931578  0.6931536  0.69315267 0.6931545  0.69315743 0.69315857]\n",
      " [0.69316405 0.6931597  0.69315684 0.69316465 0.69315493 0.6931662 ]\n",
      " [0.6931587  0.69315255 0.69315773 0.69315356 0.6931595  0.69315827]\n",
      " [0.6931558  0.6931564  0.69315046 0.6931515  0.69315207 0.6931719 ]\n",
      " [0.6931532  0.69315284 0.69315165 0.69315165 0.6931568  0.69317317]\n",
      " [0.69313    0.6931415  0.6931439  0.69315296 0.6931383  0.6931609 ]\n",
      " [0.6931324  0.6931556  0.6931423  0.6931548  0.69314003 0.6931612 ]\n",
      " [0.69315946 0.6931591  0.69315475 0.6931534  0.6931557  0.69316214]\n",
      " [0.69315517 0.69315034 0.6931549  0.69315296 0.6931546  0.6931569 ]\n",
      " [0.6931623  0.69315505 0.6931547  0.6931582  0.6931539  0.69316286]\n",
      " [0.6931577  0.6931511  0.6931502  0.693152   0.6931619  0.6931558 ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-7deec99e6b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mauc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        sess.run(train_init_op)\n",
    "        auc_list = []\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                step = sess.run(global_step)\n",
    "                \n",
    "                _X, _Y = sess.run([train_X, train_y])\n",
    "                _, _loss, _auc = sess.run([optimizer, loss, auc], feed_dict = {X: _X, Y: _Y})\n",
    "                auc_list.append(_auc)\n",
    "                \n",
    "                if (step > 0) and (step % 500 == 0):\n",
    "                    print('Step: {}, Cost: {}'.format(step, _loss))\n",
    "                    \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "                    \n",
    "#         print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
